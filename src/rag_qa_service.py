# ============================================================
#  File: src/rag_qa_service.py
# ============================================================
# [ëª¨ë“ˆ ê°œìš”]
#   - RAG ê¸°ë°˜ QA ì„¸ì…˜ ê´€ë¦¬ ëª¨ë“ˆ.
#   - RagSearcher(rag_search_gemini.py)ë¥¼ ì´ìš©í•´
#       1) ì‚¬ìš©ì ì§ˆì˜ â†’ ë²¡í„° ê²€ìƒ‰
#       2) ê²€ìƒ‰ ê²°ê³¼ ì²­í¬ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ Gemini 2.5 Flashì—ê²Œ ë‹µë³€ ìƒì„±
#   - "ì„¸ì…˜" ë‹¨ìœ„ë¡œ í˜„ì¬ ëŒ€í™”ì—ì„œ ì‚¬ìš© ì¤‘ì¸ doc_id(ì œí’ˆ/ì„¤ëª…ì„œ)ë¥¼ ê¸°ì–µí•˜ì—¬
#     í›„ì† ì§ˆì˜ì—ì„œ ì½”ë“œê°€ ìƒëµë˜ë”ë¼ë„ ë™ì¼ ë¬¸ì„œì— ëŒ€í•´ ì§ˆì˜ê°€ ì´ì–´ì§€ë„ë¡ í•¨.
#
# [í•µì‹¬ ê¸°ëŠ¥]
#   1) RAGQASession.answer()
#      - ì œí’ˆ/ëª¨ë¸ ì½”ë“œ ìë™ ì¸ì‹ + doc_id_filter ìë™ ì ìš©
#        (ìƒìœ„ì—ì„œ doc_id_filterë¥¼ ì•ˆ ë„˜ê¸¸ ë•Œ)
#      - RagSearcher.search()ë„ ìì²´ì ìœ¼ë¡œ ì½”ë“œ ì¸ì‹ ê¸°ëŠ¥ì„ ê°€ì§€ê³  ìˆì–´,
#        ë‘ ë ˆë²¨(ì„¸ì…˜/ê²€ìƒ‰ê¸°) ëª¨ë‘ì—ì„œ ì½”ë“œë¥¼ í•´ì„í•  ìˆ˜ ìˆë„ë¡ ì„¤ê³„.
#   2) Gemini 2.5 Flash ê¸°ë°˜ ë‹µë³€ ìƒì„±
#      - "ê°€ì „ì œí’ˆ ì„¤ëª…ì„œ ì „ìš© QA ì–´ì‹œìŠ¤í„´íŠ¸" ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
#      - ê·¼ê±° ì¶œì²˜ë¥¼ [doc_id p.X] í˜•ì‹ìœ¼ë¡œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
#
# [ì™¸ë¶€ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì£¼ìš” API]
#   - RAGQASession
#       session = RAGQASession()
#       result = session.answer(
#           query="SAH001 ì œí’ˆ ì‚¬ì–‘ ì•Œë ¤ì¤˜",
#           top_k=5,
#           chunk_type_filter=None,       # "text" | "figure" | None
#           doc_id_filter=None,           # ["SAH001"] | None
#       )
#       print(result.answer)
#
# ============================================================

from __future__ import annotations

import logging
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Sequence, Tuple

from google import genai
from google.genai import types

from .rag_search_gemini import (
    RagSearcher,
    SearchResult,
    RetrievedChunk,
    load_gemini_client,
)

logger = logging.getLogger(__name__)


# ----------------------------- ìƒìˆ˜ / í”„ë¡¬í”„íŠ¸ -----------------------------


DEFAULT_GEN_MODEL: str = "gemini-2.5-flash"
DEFAULT_TOP_K: int = 8

# LLMì— ë„˜ê¸¸ ë•Œ, ì²­í¬ í•˜ë‚˜ë‹¹ í…ìŠ¤íŠ¸ ìµœëŒ€ ê¸¸ì´(ë¬¸ì ìˆ˜).
# ë„ˆë¬´ ê¸´ ì²­í¬ëŠ” ... (ì¤‘ëµ) ì„ ë¶™ì—¬ ì˜ë¼ì„œ ì „ë‹¬í•´ ì»¨í…ìŠ¤íŠ¸ í­ì£¼ë¥¼ ë§‰ëŠ”ë‹¤.
MAX_CONTEXT_CHARS_PER_CHUNK: int = 1200

# QAìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
QA_SYSTEM_PROMPT: str = """
ë‹¹ì‹ ì€ 'ê°€ì „ì œí’ˆ ì‚¬ìš©ì„¤ëª…ì„œ ì „ìš©' í•œêµ­ì–´ Q&A ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

[ì—­í• ]
- ì•„ë˜ì— ì œê³µë˜ëŠ” 'ê²€ìƒ‰ëœ ì„¤ëª…ì„œ ë°œì·Œë¬¸' ì•ˆì—ì„œë§Œ ê·¼ê±°ë¥¼ ì°¾ê³  ë‹µë³€í•©ë‹ˆë‹¤.
- ì„¤ëª…ì„œì— ëª…ì‹œë˜ì§€ ì•Šì€ ì¶”ê°€ ì •ë³´(ì¶”ì¸¡, ì¼ë°˜ ìƒì‹, ì¸í„°ë„· ì •ë³´ ë“±)ë¥¼
  ìƒˆë¡œ ì§€ì–´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤.
- ë‹µì´ ì„¤ëª…ì„œì— ëª…í™•íˆ ì—†ìœ¼ë©´, ëª¨ë¥´ëŠ” ë‚´ìš©ì„ ì§€ì–´ë‚´ì§€ ë§ê³ 
  "í•´ë‹¹ ì„¤ëª…ì„œ ë°œì·Œë¬¸ì—ì„œëŠ” ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤" ë¼ê³  ì†”ì§í•˜ê²Œ ë§í•©ë‹ˆë‹¤.
- ì„¤ëª…ì„œëŠ” í•œêµ­ ì†Œë¹„ìë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ìë£Œì´ë¯€ë¡œ,
  ì•ˆì „, ì‚¬ìš©ë°©ë²•, ì£¼ì˜ì‚¬í•­ ë“±ì„ ì¹œì ˆí•˜ê³  ì‰½ê²Œ ì„¤ëª…í•©ë‹ˆë‹¤.

[ë‹µë³€ ì›ì¹™]
1. ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ì œí’ˆ/ëª¨ë¸ì— ëŒ€í•´ì„œë§Œ ë‹µí•©ë‹ˆë‹¤.
2. ì•ˆì „ê³¼ ê´€ë ¨ëœ ë‚´ìš©ì´ ìˆë‹¤ë©´, í•­ìƒ ëˆˆì— ì˜ ë„ê²Œ ê°•ì¡°í•˜ì—¬ ì•ˆë‚´í•©ë‹ˆë‹¤.
3. ì„¤ëª…ì„œì˜ í‘œí˜„ì„ ê·¸ëŒ€ë¡œ ë³µì‚¬í•˜ê¸°ë³´ë‹¤ëŠ”, ì´í•´í•˜ê¸° ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì§€ë§Œ
   ì˜ë¯¸ë¥¼ ì™œê³¡í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
4. ì—¬ëŸ¬ ë°œì·Œë¬¸ì´ ìˆì„ ê²½ìš°, ì„œë¡œ ëª¨ìˆœë˜ì§€ ì•ŠëŠ” ì„ ì—ì„œ í†µí•©í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤.
5. ì¶œì²˜ í‘œì‹œë¥¼ í•  ë•Œì—ëŠ”, ë¬¸ì¥ ëì— ëŒ€ê´„í˜¸ë¡œ [doc_id p.í˜ì´ì§€] í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
   ì˜ˆ) íˆí„°ì˜ ì‚¬ì´ì¦ˆëŠ” ê°€ë¡œ 590mm, ë†’ì´ 1570mmì…ë‹ˆë‹¤. [SAH001 p.3]

[ì¤‘ìš”]
- ë°œì·Œë¬¸ì— í¬ê¸°/ì‚¬ì–‘/ì œì› ì •ë³´ê°€ ìˆë‹¤ë©´, ìˆ«ìì™€ ë‹¨ìœ„ë¥¼ ì •í™•í•˜ê²Œ ê·¸ëŒ€ë¡œ ì˜®ê¹ë‹ˆë‹¤.
- ë°œì·Œë¬¸ì´ ì—†ê±°ë‚˜, ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ë‹¤ë©´ ê·¸ ì‚¬ì‹¤ì„ ë¶„ëª…íˆ ì–¸ê¸‰í•©ë‹ˆë‹¤.
"""


# ----------------------------- ë°ì´í„° êµ¬ì¡° ì •ì˜ -----------------------------


@dataclass
class QAResult:
    """
    RAGQASession.answer() ì˜ ë°˜í™˜ ê²°ê³¼.

    - answer: LLMì´ ìƒì„±í•œ ìµœì¢… ë‹µë³€ í…ìŠ¤íŠ¸
    - search_result: RagSearcher.search() ê²€ìƒ‰ ê²°ê³¼ ì›ë³¸
    - used_doc_id_filter:
        ì‹¤ì œ ê²€ìƒ‰ì— ì‚¬ìš©ëœ doc_id_filter (ì—†ìœ¼ë©´ None)
    - doc_ids_from_codes:
        ì´ë²ˆ ì§ˆì˜ì—ì„œ "ì œí’ˆ/ëª¨ë¸ ì½”ë“œ" ë¥¼ ì¸ì‹í•´ ì–»ì€ doc_id ëª©ë¡
        (ì„¸ì…˜ ê¸°ì–µ/ëª…ì‹œ filterê°€ ìš°ì„ ì´ë©´ ë¹ˆ ë¦¬ìŠ¤íŠ¸)
    - used_session_doc_filter:
        True  â†’ ì„¸ì…˜ì´ ê¸°ì–µí•˜ê³  ìˆë˜ doc_idë¥¼ ì¬ì‚¬ìš©í•œ ê²½ìš°
        False â†’ ìƒˆë¡œ ê°ì§€ë˜ì—ˆê±°ë‚˜, ì•„ì˜ˆ doc_id í•„í„° ì—†ì´ ê²€ìƒ‰í•œ ê²½ìš°
    """

    question: str
    answer: str
    search_result: SearchResult
    used_doc_id_filter: Optional[List[str]] = None
    doc_ids_from_codes: List[str] = field(default_factory=list)
    used_session_doc_filter: bool = False


# ----------------------------- RAGQASession êµ¬í˜„ -----------------------------


class RAGQASession:
    """
    ë‹¨ì¼ ì‚¬ìš©ì ëŒ€í™” ì„¸ì…˜ ë‹¨ìœ„ë¡œ
      - ê²€ìƒ‰ê¸°(RagSearcher)
      - ìƒì„±ëª¨ë¸(Gemini 2.5 Flash)
      - í˜„ì¬ ë¬¸ì„œ(doc_id) ì»¨í…ìŠ¤íŠ¸
      - ëŒ€í™” ì´ë ¥(history)
    ë¥¼ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤.

    ğŸ”¹ ì œí’ˆ/ëª¨ë¸ ì½”ë“œ ì¸ì‹ + doc_id_filter ìë™ ì ìš© ë¡œì§
    ----------------------------------------------------
    1) answer() í˜¸ì¶œ ì‹œ ì¸ìì— doc_id_filterê°€ ëª…ì‹œë˜ë©´ ê·¸ ê°’ì„ ìµœìš°ì„  ì‚¬ìš©.
       - self.current_doc_ids ë¥¼ í•´ë‹¹ ê°’ìœ¼ë¡œ ê°±ì‹ .
    2) ëª…ì‹œëœ doc_id_filterê°€ ì—†ë‹¤ë©´, ê²€ìƒ‰ê¸°(RagSearcher)ì˜
       extract_model_codes_from_query() / resolve_doc_ids_for_codes()
       ë¥¼ ì´ìš©í•´ ì§ˆì˜ë¬¸ì—ì„œ ì½”ë“œ(SBDH-T1000, SAH001 ë“±)ë¥¼ ì¶”ì¶œ.
       - ë§¤í•‘ë˜ëŠ” doc_idê°€ ìˆìœ¼ë©´ ê·¸ ëª©ë¡ì„ doc_id_filterë¡œ ì‚¬ìš©í•˜ê³ ,
         self.current_doc_idsì— ì €ì¥ (â†’ ë‹¤ìŒ í„´ì—ì„œ ì œí’ˆëª… ìƒëµ ê°€ëŠ¥).
    3) 1, 2 ë‘˜ ë‹¤ ì‹¤íŒ¨í•˜ê³ , ì„¸ì…˜ì´ ì´ë¯¸ current_doc_idsë¥¼ ê¸°ì–µí•˜ê³  ìˆë‹¤ë©´
       - ì´ì „ í„´ì—ì„œ ì‚¬ìš©í•˜ë˜ doc_id_filterë¥¼ ê·¸ëŒ€ë¡œ ì¬ì‚¬ìš©.
    4) ê·¸ ì–´ë–¤ ê²ƒë„ ì—†ìœ¼ë©´ doc_id_filter ì—†ì´ ì „ì²´ ì„¤ëª…ì„œì— ëŒ€í•´ ê²€ìƒ‰.

    * RagSearcher.search() ë‚´ë¶€ì—ë„
      "doc_id_filterê°€ ë¹„ì–´ ìˆì„ ë•Œ, ì§ˆì˜ì—ì„œ ì½”ë“œ ê°ì§€ â†’ ìë™ í•„í„°ë§"
      ë¡œì§ì´ ìˆìœ¼ë¯€ë¡œ, ìƒìœ„(ì„¸ì…˜)ì™€ í•˜ìœ„(ê²€ìƒ‰ê¸°) ë‘ ë ˆë²¨ì—ì„œ
      ì½”ë“œ ì¸ì‹ì´ ë™ì‘í•˜ëŠ” êµ¬ì¡°ì´ë‹¤.
    """

    def __init__(
        self,
        searcher: Optional[RagSearcher] = None,
        gen_model: str = DEFAULT_GEN_MODEL,
        temperature: float = 0.2,
        top_k: int = DEFAULT_TOP_K,
    ) -> None:
        # ê²€ìƒ‰ê¸° (ì—†ìœ¼ë©´ ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ìƒì„±)
        self.searcher: RagSearcher = searcher or RagSearcher()

        # ìƒì„± ëª¨ë¸ ê´€ë ¨ ì„¤ì •
        self.gen_model: str = gen_model
        self.temperature: float = temperature
        self.top_k: int = top_k

        # LLM í´ë¼ì´ì–¸íŠ¸ (rag_search_gemini ì˜ ìœ í‹¸ ì¬ì‚¬ìš©)
        self._client: genai.Client = load_gemini_client()

        # ì„¸ì…˜ ìƒíƒœ
        self.history: List[Dict[str, str]] = []  # {"role": "user"/"assistant", "content": "..."}
        self.current_doc_ids: Optional[List[str]] = None  # í˜„ì¬ ì„¸ì…˜ì—ì„œ ì„ íƒëœ doc_id ëª©ë¡
        self.last_question: Optional[str] = None

        logger.info(
            "[QA] RAGQASession ì´ˆê¸°í™” ì™„ë£Œ (gen_model=%s, top_k=%d)",
            self.gen_model,
            self.top_k,
        )

    # ---------- ì„¸ì…˜ ê´€ë¦¬ ìœ í‹¸ ----------

    def reset(self) -> None:
        """
        ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ëŒ€í™” ì´ë ¥, í˜„ì¬ doc_id ì»¨í…ìŠ¤íŠ¸ ë“±).
        """
        self.history.clear()
        self.current_doc_ids = None
        self.last_question = None
        logger.info("[QA] RAGQASession ìƒíƒœê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # ---------- doc_id_filter ê²°ì • ë¡œì§ ----------

    def _decide_doc_id_filter(
        self,
        query: str,
        explicit_doc_ids: Optional[Sequence[str]] = None,
    ) -> Tuple[Optional[List[str]], List[str], bool]:
        """
        í˜„ì¬ í„´ì—ì„œ ì‚¬ìš©í•  doc_id_filterë¥¼ ê²°ì •í•œë‹¤.

        Returns:
            (effective_doc_ids, doc_ids_from_codes, used_session_doc_filter)

            - effective_doc_ids      : ì‹¤ì œ search()ì— ë„˜ê¸¸ doc_id_filter (ì—†ìœ¼ë©´ None)
            - doc_ids_from_codes     : ì´ë²ˆ ì§ˆì˜ì—ì„œ ì½”ë“œ ì¸ì‹ìœ¼ë¡œ ì–»ì–´ì§„ doc_id ëª©ë¡
            - used_session_doc_filter: ì„¸ì…˜ì˜ current_doc_idsë¥¼ ì¬ì‚¬ìš©í–ˆëŠ”ì§€ ì—¬ë¶€
        """
        # 1) ëª…ì‹œì ìœ¼ë¡œ doc_id_filter ì¸ìê°€ ë„˜ì–´ì˜¨ ê²½ìš° â†’ ìµœìš°ì„ 
        if explicit_doc_ids:
            dedup = list(
                dict.fromkeys(
                    str(d).strip() for d in explicit_doc_ids if str(d).strip()
                )
            )
            if dedup:
                self.current_doc_ids = dedup
                logger.info(
                    "[QA] ìƒìœ„ ë ˆë²¨ì—ì„œ ëª…ì‹œëœ doc_id_filter ì‚¬ìš©: %s",
                    ",".join(dedup),
                )
                return dedup, [], False

        # 2) ì§ˆì˜ë¬¸ì—ì„œ ì œí’ˆ/ëª¨ë¸ ì½”ë“œ ì¶”ì¶œ â†’ doc_id ë§¤í•‘
        codes = self.searcher.extract_model_codes_from_query(query)
        if codes:
            doc_ids_from_codes = self.searcher.resolve_doc_ids_for_codes(codes)
            if doc_ids_from_codes:
                self.current_doc_ids = doc_ids_from_codes
                logger.info(
                    "[QA] ì§ˆì˜ì—ì„œ ëª¨ë¸ ì½”ë“œ ê°ì§€ %s â†’ doc_id_filter ì„¤ì •: %s",
                    ",".join(codes),
                    ",".join(doc_ids_from_codes),
                )
                return doc_ids_from_codes, doc_ids_from_codes, False
            else:
                logger.info(
                    "[QA] ì§ˆì˜ì—ì„œ ì½”ë“œ %s ê°ì§€ë˜ì—ˆìœ¼ë‚˜ ë§¤í•‘ë˜ëŠ” doc_id ì—†ìŒ",
                    ",".join(codes),
                )

        # 3) ì„¸ì…˜ì—ì„œ ê¸°ì–µ ì¤‘ì¸ doc_id ì»¨í…ìŠ¤íŠ¸ ì¬ì‚¬ìš©
        if self.current_doc_ids:
            logger.info(
                "[QA] ì„¸ì…˜ ì»¨í…ìŠ¤íŠ¸ì˜ doc_id_filter ì¬ì‚¬ìš©: %s",
                ",".join(self.current_doc_ids),
            )
            return list(self.current_doc_ids), [], True

        # 4) ì•„ë¬´ í•„í„°ë„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ (ì „ì²´ ë¬¸ì„œ ëŒ€ìƒ ê²€ìƒ‰)
        logger.info("[QA] doc_id_filter ì—†ì´ ì „ì²´ ì„¤ëª…ì„œ ëŒ€ìƒ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
        return None, [], False

    # ---------- ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ êµ¬ì„± ----------

    @staticmethod
    def _format_chunk_for_context(chunk: RetrievedChunk) -> str:
        """
        LLMì— ë„˜ê¸¸ ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸ í•œ ë©ì–´ë¦¬ë¡œ ë³€í™˜.

        ì˜ˆ:
            [SAH001 p.3 TEXT]
            (ì„¹ì…˜: ì œí’ˆ ì‚¬ì–‘)
            ì œí’ˆ ì‚¬ì–‘ | í’ˆ ëª… | ê°€ìŠ¤ íˆí„° ...

        - ì²­í¬ ë³¸ë¬¸ì€ MAX_CONTEXT_CHARS_PER_CHUNK ê¸¸ì´ê¹Œì§€ë§Œ ì‚¬ìš©í•˜ê³ ,
          ë„˜ì–´ê°€ëŠ” ê²½ìš° "(ì¤‘ëµ)" í‘œì‹œë¥¼ ë§ë¶™ì¸ë‹¤.
        """
        doc_id = chunk.doc_id
        page = chunk.meta.get("page") or chunk.meta.get("page_start")
        page_info = f"p.{page}" if page is not None else "p.?"
        chunk_type = (chunk.chunk_type or "text").upper()

        section = chunk.meta.get("section_title") or chunk.meta.get("category") or ""
        section_line = f"(ì„¹ì…˜: {section})" if section else ""

        header = f"[{doc_id} {page_info} {chunk_type}]"
        body = (chunk.text or "").strip()

        # ê³¼ë„í•˜ê²Œ ê¸´ ì²­í¬ëŠ” ì˜ë¼ì„œ ì „ë‹¬
        if body and len(body) > MAX_CONTEXT_CHARS_PER_CHUNK:
            body = body[:MAX_CONTEXT_CHARS_PER_CHUNK].rstrip() + "\n...(ì¤‘ëµ)..."

        parts = [header]
        if section_line:
            parts.append(section_line)
        if body:
            parts.append(body)

        return "\n".join(parts)

    def _build_context_block(self, search_result: SearchResult) -> str:
        """
        ì—¬ëŸ¬ ì²­í¬ë“¤ì„ í•˜ë‚˜ì˜ ì»¨í…ìŠ¤íŠ¸ ë¸”ë¡ ë¬¸ìì—´ë¡œ í•©ì¹œë‹¤.
        """
        formatted_chunks: List[str] = [
            self._format_chunk_for_context(ch) for ch in search_result.chunks
        ]
        if not formatted_chunks:
            return "(ê²€ìƒ‰ëœ ì„¤ëª…ì„œ ë°œì·Œë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.)"
        return "\n\n-----\n\n".join(formatted_chunks)

    # ---------- LLM í˜¸ì¶œ ----------

    def _call_llm(
        self,
        question: str,
        search_result: SearchResult,
    ) -> str:
        """
        Gemini 2.5 Flashë¥¼ í˜¸ì¶œí•´ ìµœì¢… ë‹µë³€ì„ ìƒì„±.
        """
        context_block = self._build_context_block(search_result)

        # í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì‹œìŠ¤í…œ ì§€ì‹œ + ì»¨í…ìŠ¤íŠ¸ + ì§ˆë¬¸ì„ í•©ì¹œë‹¤.
        prompt = (
            QA_SYSTEM_PROMPT.strip()
            + "\n\n"
            + "==============================\n"
            + "[ê²€ìƒ‰ëœ ì„¤ëª…ì„œ ë°œì·Œë¬¸]\n"
            + "==============================\n"
            + context_block
            + "\n\n"
            + "==============================\n"
            + "[ì‚¬ìš©ì ì§ˆë¬¸]\n"
            + "==============================\n"
            + question.strip()
            + "\n"
        )

        logger.info("[QA] Gemini ë‹µë³€ ìƒì„± ì‹œì‘ (context_chunks=%d)", len(search_result.chunks))

        resp = self._client.models.generate_content(
            model=self.gen_model,
            contents=[prompt],
            config=types.GenerateContentConfig(
                temperature=self.temperature,
            ),
        )

        # ì‘ë‹µ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ
        text_parts: List[str] = []
        if getattr(resp, "candidates", None):
            for cand in resp.candidates:
                if not cand.content:
                    continue
                for part in cand.content.parts:
                    if hasattr(part, "text") and part.text:
                        text_parts.append(part.text)
        if not text_parts and hasattr(resp, "text") and resp.text:
            text_parts.append(resp.text)

        answer_text = "\n".join(text_parts).strip()
        if not answer_text:
            logger.warning("[QA] LLM ì‘ë‹µì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
            answer_text = (
                "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì œê³µëœ ì„¤ëª…ì„œ ë°œì·Œë¬¸ë§Œìœ¼ë¡œëŠ” "
                "ì ì ˆí•œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            )

        return answer_text

    # ---------- ë©”ì¸ API: answer() ----------

    def answer(
        self,
        query: str,
        top_k: Optional[int] = None,
        chunk_type_filter: Optional[str] = None,     # "text" | "figure" | None
        doc_id_filter: Optional[Sequence[str]] = None,
    ) -> QAResult:
        """
        ì‚¬ìš©ìì˜ ìì—°ì–´ ì§ˆì˜(query)ì— ëŒ€í•´ RAG ê¸°ë°˜ ë‹µë³€ì„ ìƒì„±í•œë‹¤.

        1) ì„¸ì…˜/ì§ˆì˜ ê¸°ë°˜ìœ¼ë¡œ doc_id_filter ê²°ì •
        2) RagSearcher.search() í˜¸ì¶œë¡œ ê´€ë ¨ ì²­í¬ ê²€ìƒ‰
        3) ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ LLM í˜¸ì¶œ
        4) ì„¸ì…˜ ì´ë ¥/ì»¨í…ìŠ¤íŠ¸ ê°±ì‹  í›„ QAResult ë°˜í™˜
        """
        q = query.strip()
        if not q:
            raise ValueError("ë¹ˆ ë¬¸ìì—´ì€ ì§ˆì˜ë¡œ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 0) ì‚¬ìš©í•  top_k ê²°ì •
        effective_top_k = top_k if (top_k is not None and top_k > 0) else self.top_k

        # 1) ì´ë²ˆ í„´ì—ì„œ ì‚¬ìš©í•  doc_id_filter ê²°ì •
        effective_doc_ids, doc_ids_from_codes, used_session_filter = (
            self._decide_doc_id_filter(q, explicit_doc_ids=doc_id_filter)
        )

        # 2) ê²€ìƒ‰ ìˆ˜í–‰
        search_result: SearchResult = self.searcher.search(
            query=q,
            top_k=effective_top_k,
            chunk_type_filter=chunk_type_filter,
            doc_id_filter=effective_doc_ids,
        )

        # 3) LLM í˜¸ì¶œë¡œ ìµœì¢… ë‹µë³€ ìƒì„±
        answer_text: str = self._call_llm(
            question=q,
            search_result=search_result,
        )

        # 4) ì„¸ì…˜ ì´ë ¥ ì—…ë°ì´íŠ¸
        self.history.append({"role": "user", "content": q})
        self.history.append({"role": "assistant", "content": answer_text})
        self.last_question = q

        return QAResult(
            question=q,
            answer=answer_text,
            search_result=search_result,
            used_doc_id_filter=list(effective_doc_ids) if effective_doc_ids else None,
            doc_ids_from_codes=list(doc_ids_from_codes),
            used_session_doc_filter=used_session_filter,
        )


# ----------------------------- ìŠ¤í¬ë¦½íŠ¸ë¡œ ì§ì ‘ ì‹¤í–‰ ì‹œ -----------------------------


def _interactive_cli() -> None:
    """
    ê°„ë‹¨í•œ CLI í…ŒìŠ¤íŠ¸ìš©:
        (.venv) > python -m src.rag_qa_service
    """
    from .rag_search_gemini import configure_logging

    configure_logging()
    session = RAGQASession()

    print("\nâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ RAG QA í…ŒìŠ¤íŠ¸ (rag_qa_service) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€")
    print("ì œí’ˆ/ëª¨ë¸ ì½”ë“œ ì¸ì‹ + doc_id_filter ìë™ ì ìš©ì´ í¬í•¨ëœ QA ì„¸ì…˜ì…ë‹ˆë‹¤.")
    print("ëª…ë ¹ì–´:")
    print("  /reset       ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (í˜„ì¬ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ í¬í•¨)")
    print("  /quit, /exit ì¢…ë£Œ")
    print("ì§ˆë¬¸ì„ ì…ë ¥í•˜ë©´ ëª¨ë¸ì˜ ë‹µë³€ê³¼ í•¨ê»˜ ì‚¬ìš©ëœ ê·¼ê±° ìŠ¤ë‹ˆí« ì •ë³´ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.\n")

    while True:
        try:
            q = input("ì§ˆë¬¸: ").strip()
        except (EOFError, KeyboardInterrupt):
            break

        if not q:
            continue
        if q.lower() in ("/quit", "/exit"):
            break
        if q.lower() == "/reset":
            session.reset()
            print("â†’ ì„¸ì…˜ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n")
            continue

        try:
            qa_result = session.answer(q, top_k=5)
        except Exception as e:  # pylint: disable=broad-except
            logger.exception("ì§ˆì˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: %s", e)
            print(f"[ì˜¤ë¥˜] {e}\n")
            continue

        # ëª¨ë¸ ë‹µë³€ ì¶œë ¥
        print("\n[ëª¨ë¸ ë‹µë³€]")
        print(qa_result.answer)
        print()

        # ë©”íƒ€ ì •ë³´ ì¶œë ¥
        if qa_result.used_doc_id_filter:
            src_info = ",".join(qa_result.used_doc_id_filter)
            if qa_result.doc_ids_from_codes:
                print(f"[INFO] doc_id_filter={src_info} (ì§ˆì˜ì˜ ì œí’ˆ/ëª¨ë¸ ì½”ë“œì—ì„œ ìë™ ì¶”ë¡ )")
            elif qa_result.used_session_doc_filter:
                print(f"[INFO] doc_id_filter={src_info} (ì„¸ì…˜ì—ì„œ ê¸°ì–µ ì¤‘ì¸ ë¬¸ì„œ ì»¨í…ìŠ¤íŠ¸ ì¬ì‚¬ìš©)")
            else:
                print(f"[INFO] doc_id_filter={src_info} (ìƒìœ„ì—ì„œ ëª…ì‹œ/ì§ì ‘ ì§€ì •)")
        else:
            print("[INFO] doc_id_filter ì—†ìŒ (ì „ì²´ ì„¤ëª…ì„œ ëŒ€ìƒ ê²€ìƒ‰)")

        # ê·¼ê±° ìŠ¤ë‹ˆí«ë“¤ ìš”ì•½
        print(f"[INFO] ê²€ìƒ‰ ì»¨í…ìŠ¤íŠ¸: {len(qa_result.search_result.chunks)}ê°œ ìŠ¤ë‹ˆí« ì‚¬ìš©")
        for i, ch in enumerate(qa_result.search_result.chunks, start=1):
            doc_id = ch.doc_id
            page = ch.meta.get("page") or ch.meta.get("page_start")
            page_info = f"p.{page}" if page is not None else "p.?"
            section = ch.meta.get("section_title") or ch.meta.get("category") or ""
            section_info = f" | {section}" if section else ""
            print(
                f"  [{i}] {doc_id} {page_info}{section_info} "
                f"| type={ch.chunk_type} | score={ch.score:.4f}"
            )
        print()

    print("ì¢…ë£Œí•©ë‹ˆë‹¤.")


if __name__ == "__main__":
    _interactive_cli()
